{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T10:46:15.897785Z",
     "start_time": "2025-05-30T10:45:56.797532Z"
    }
   },
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('../data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('../data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:13<00:00, 1.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 201kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:02<00:00, 1.92MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:47:47.173417Z",
     "start_time": "2025-05-30T10:47:47.146248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ],
   "id": "b000fd0c96da27e1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:47:48.459107Z",
     "start_time": "2025-05-30T10:47:48.449704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "id": "212a9c161236d075",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:47:51.756694Z",
     "start_time": "2025-05-30T10:47:49.183170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ],
   "id": "b2ef8167b484212",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:48:21.549039Z",
     "start_time": "2025-05-30T10:48:15.451621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ],
   "id": "44cca9d0d18d5d3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:48:30.182724Z",
     "start_time": "2025-05-30T10:48:24.602131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorboard import program\n",
    "import webbrowser\n",
    "\n",
    "log_dir = \"runs\"\n",
    "tb = program.TensorBoard()\n",
    "tb.configure(argv=[None, '--logdir', log_dir])\n",
    "url = tb.launch()\n",
    "print(f\"TensorBoard started at {url}\")\n",
    "webbrowser.open(url)"
   ],
   "id": "b4f3d980da55261",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboard:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard started at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorboard:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:48:33.435283Z",
     "start_time": "2025-05-30T10:48:32.917656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ],
   "id": "e04a6ced4279f327",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:49:05.479763Z",
     "start_time": "2025-05-30T10:49:05.279098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ],
   "id": "d47d600fd0e5d625",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:49:07.313210Z",
     "start_time": "2025-05-30T10:49:07.301331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ],
   "id": "738767373d73b1dd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:51:14.769278Z",
     "start_time": "2025-05-30T10:49:17.854330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ],
   "id": "83b71818def5fe4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:51:33.339518Z",
     "start_time": "2025-05-30T10:51:20.543096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ],
   "id": "f0dbae802cd24f03",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "860ece53002fe440"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
